{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying all of MNIST\n",
    "\n",
    "Current SOA does only 2 digits, `IBM=(0,1)`, `Google=(3,6)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import qiskit\n",
    "from qiskit.visualization import *\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit.utils import algorithm_globals\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "import time as t\n",
    "\n",
    "from utils import gtt, make_filt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000;\n",
    "n_test = 100; \n",
    "qubits = 13\n",
    "shots = 256\n",
    "threads = 8\n",
    "\n",
    "train_loader, test_loader = gtt(n_train, [i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unweight(dic):\n",
    "    return [k for k, v in dic.items() for i in range(v)]\n",
    "    \n",
    "def get_probabilities(results):\n",
    "\n",
    "    if isinstance(results, dict):\n",
    "        results = [results]\n",
    "\n",
    "    probabilities = []\n",
    "    for result in results:\n",
    "        arr = np.mean([list(map(int, x)) for x in unweight(result)], axis=0)\n",
    "        probabilities.append(arr)\n",
    "    \n",
    "    return probabilities[0] if len(probabilities)==1 else probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "\"IN IMAGE\" = Conv = Conv = DropOut = Linear\n",
    "||\n",
    "Quantum\n",
    "||\n",
    "Linear = \"OUTPIT\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    def __init__(self, n_qubits):\n",
    "        self.threads = threads;\n",
    "        circs = []\n",
    "        for i in range(threads): # Creates 8 parallel identical circuits\n",
    "            circ = qiskit.QuantumCircuit(qubits);\n",
    "            all_qubits = [i for i in range(qubits)]\n",
    "            circ.h(all_qubits)\n",
    "            # Parametrisation\n",
    "            params = [qiskit.circuit.Parameter('theta')]\n",
    "            circ.rx(params[0], all_qubits)\n",
    "            # run\n",
    "            circ.measure_all()\n",
    "            \n",
    "            param_dict = {param: np.random.random() for param in params}\n",
    "            bound_circuit = circ.assign_parameters(parameters = param_dict)\n",
    "            \n",
    "            circs.append(bound_circuit);\n",
    "\n",
    "        self.circuits = circs;\n",
    "\n",
    "    def runner(self, circuit):\n",
    "        # backend = qiskit.Aer.get_backend('aer_simulator')\n",
    "        backend = AerSimulator()\n",
    "        \n",
    "        result = qiskit.execute(circuit, backend, shots=int(shots/threads)).result()\n",
    "        result = get_probabilities(result.get_counts(circuit))\n",
    "        return result\n",
    "\n",
    "    def run(self, inputs):\n",
    "        reses = None;\n",
    "        with ThreadPoolExecutor(max_workers=len(self.circuits)) as executor:\n",
    "            reses = list(executor.map(self.runner, self.circuits))\n",
    "\n",
    "        return np.average(reses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "\n",
    "    @staticmethod  # Note: the @staticmethod decorator is not strictly necessary here\n",
    "    def forward(ctx, input, quantum_circuit):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        ctx.shift = np.pi / 2;  # Store the shift value for the backward pass\n",
    "        # Store the quantum circuit for the backward pass\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        results = []; \n",
    "        for i in range(len(input)):\n",
    "            expectation_z = ctx.quantum_circuit.run(input[i].tolist())   \n",
    "            results.append(torch.tensor(np.array([expectation_z])))\n",
    "\n",
    "        # Save the input and the result for the backward pass\n",
    "        results = torch.stack(results).squeeze(1)\n",
    "        ctx.save_for_backward(input, results)\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "        input, expectation_z = ctx.saved_tensors  # Load the saved tensors\n",
    "        # Convert the input to a numpy array\n",
    "        input_list = np.array(input.tolist())\n",
    "        \n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift # Shift right\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift # Shift left\n",
    "\n",
    "        gradients = []\n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i]) # Run the quantum circuit for the right shift\n",
    "            expectation_left = ctx.quantum_circuit.run(shift_left[i]) # Run the quantum circuit for the left shift\n",
    "\n",
    "            gradient = torch.tensor(np.array([expectation_right])) - \\\n",
    "                torch.tensor(np.array([expectation_left])) # Compute the gradient\n",
    "            gradients.append(gradient)\n",
    "            \n",
    "        # gradients = np.array([gradients]).T\n",
    "        gradients = torch.stack(gradients).squeeze(1)\n",
    "        return gradients * grad_output.float(), None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return HybridFunction.apply(input, self.quantum_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=4)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=4)\n",
    "        out_conv1 = F.max_pool2d(self.conv1(torch.rand(1,1,28,28)), 2); \n",
    "        out_conv2 = F.max_pool2d(self.conv2(out_conv1), 2)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(out_conv2.view(1,-1).shape[1], qubits)\n",
    "        self.hybrid = Hybrid()\n",
    "        out_hybrid = self.hybrid(torch.rand(qubits,qubits))\n",
    "        self.fc2 = nn.Linear(out_hybrid.shape[1], 10)\n",
    "        \n",
    "#         each conv reduces size, the more the better so that we ensure that the quantum does the heavy lifting\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x) # We don't relu this to prevent learning, we pass as-is to QC\n",
    "        x = self.hybrid(x).type(torch.FloatTensor)\n",
    "        x = self.fc2(x)\n",
    "        return x; \n",
    "    \n",
    "model = Net();\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = [3]\n",
    "\n",
    "model.train()\n",
    "\n",
    "outputs = []\n",
    "targets = []\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    times = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        now = t.time()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        outputs.append(torch.argmax(output))\n",
    "        targets.append(target)\n",
    "        \n",
    "        loss = loss_func(output, target) # Loss\n",
    "\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Optimize the weights\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        times.append(t.time() - now)\n",
    "    \n",
    "    print(f\"Avg Itr Time: {np.round(np.average(times),1)}s x {len(times)} itrs = {np.round(np.sum(times)/60,1)}min\")\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    \n",
    "    diff = np.abs(loss_list[-1] - loss_list[-2]) /loss_list[-1]; \n",
    "    if diff <= 0.001: # Early stopping criterial loss diff = 0.1%\n",
    "        break;\n",
    "    \n",
    "    print(f'Training [{100. * (epoch + 1) / epochs:.0f}%]\\tLoss: {loss_list[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('CrossEntropy Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "        sum(total_loss) / len(total_loss),\n",
    "        correct / len(test_loader) * 100)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model(data)\n",
    "        print(output)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "html{filter:invert(1)}\n",
    "\n",
    "div.prompt{opacity: 0.5;}\n",
    "\n",
    ".btn-default{border-color: transparent;}\n",
    "\n",
    "#header-container{display:none !important;}\n",
    "\n",
    "div.cell.selected, div.cell.selected.jupyter-soft-selected{border-color: transparent;}\n",
    "</style>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
