{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import qiskit\n",
    "from qiskit.visualization import *\n",
    "import qiskit_machine_learning as qml\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    CrossEntropyLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import gtt, make_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10  # Set number of epochs\n",
    "filt, digits = make_filt([0,1,3,4,8])\n",
    "\n",
    "qubits = digits\n",
    "n_train = 200*digits\n",
    "n_test = int(n_train/10);\n",
    "\n",
    "print(\n",
    "f'using {qubits} Qubits @{n_train} datapoints: {filt} for {epochs} epochs'\n",
    ")\n",
    "train_loader, test_loader = gtt(n_train, filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bd854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create QNN\n",
    "def create_qnn(qubits):\n",
    "    feature_map = qiskit.circuit.library.ZZFeatureMap(qubits)\n",
    "    ansatz = qiskit.circuit.library.EfficientSU2(\n",
    "                            qubits, su2_gates=['rx', 'ry', 'rz'], \n",
    "                            entanglement='circular', reps=1\n",
    "    )\n",
    "    qc = qiskit.circuit.QuantumCircuit(qubits)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "    \n",
    "#     print(f\"Circuit Depth {qc.depth()}\", qc)\n",
    "    transpiled = qiskit.compiler.transpile(qc)\n",
    "    print(transpiled)\n",
    "\n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = qml.neural_networks.EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "qnn4 = create_qnn(qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self, qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 6, kernel_size=3)\n",
    "        self.conv2 = Conv2d(6, 16, kernel_size=3)\n",
    "        self.conv3 = Conv2d(16, qubits, kernel_size=3) # outputs 1x10\n",
    "        self.dropout = Dropout2d()\n",
    "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        self.fc3 = Linear(1, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc3(x)\n",
    "        return x; \n",
    "\n",
    "model4 = Net(qnn4)\n",
    "print(model4)\n",
    "print(model4(torch.randn(1,1,28,28))) # Just testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afba82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "optimizer = Adam(model4.parameters(), lr=0.01)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "loss_func = CrossEntropyLoss()\n",
    "\n",
    "# Start training\n",
    "loss_list = [2.3]  # Store loss history\n",
    "model4.train()  # Set model to training mode\n",
    "\n",
    "itrs = len(train_loader)\n",
    "logspan = int(itrs*12/100) # 12%\n",
    "\n",
    "print(f\"Running training for {qubits} Qubits @{itrs} itrs/epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    times = []\n",
    "    now = t.time()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        z = t.time()\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        output = model4(data)  # Forward pass\n",
    "        loss = loss_func(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        \n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  # Store loss\n",
    "        z = t.time() - z;\n",
    "        if ((batch_idx%(logspan))==0): print(f\"{int(z)*logspan} sec/{logspan}itrs\")\n",
    "    \n",
    "    scheduler.step()\n",
    "    end = int((t.time() - now)/60)+1\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"Trained [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]), \n",
    "          f\"in {end} min \\t(est. {int((epochs-epoch)*end)} min left)\")\n",
    "    \n",
    "    diff = np.abs(loss_list[-1] - loss_list[-2]) /loss_list[-1]; \n",
    "    if diff <= 0.0005: # Early stopping criterial loss diff = 0.1%\n",
    "        print(\"Î¤raining Complete\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss convergence\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Neg. Log Likelihood Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732abd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for (data, target) in test_loader:\n",
    "        output = model4(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "                sum(total_loss) / len(total_loss),\n",
    "                correct / len(test_loader) * 100)\n",
    "            )\n",
    "    print(f\"Perfectly Random would be {int(100/digits)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389455ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted labels\n",
    "\n",
    "n_samples_show = 15\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model4.eval()\n",
    "with no_grad():\n",
    "    for (data, target) in test_loader:\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model4(data[0:1])\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap=\"viridis\")\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title(\"{}\".format(pred.item()))\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc742639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fa1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774aa964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "html{filter:invert(0.86)}\n",
    "\n",
    "div.prompt{opacity: 0.5;}\n",
    "\n",
    ".btn-default{border-color: transparent;}\n",
    "\n",
    "#header-container{display:none !important;}\n",
    "\n",
    "div.cell.selected, div.cell.selected.jupyter-soft-selected{border-color: transparent;}\n",
    "</style>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
